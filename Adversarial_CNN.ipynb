{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvRjnhpfYy2PoC/K/R1FKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Adversarial_Attack_Defense/blob/main/Adversarial_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from flautim.pytorch.Model import Model\n",
        "\n",
        "\n",
        "class Model(Model):\n",
        "    def __init__(self, context, num_classes=10, **kwargs):\n",
        "        super(Model, self).__init__(context, name=\"LeNet5\", **kwargs)\n",
        "\n",
        "        # entrada esperada -> imagens preta e branca 1x28x28\n",
        "        #caso tenha cores (RGB)\n",
        "        #self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1)\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "\n",
        "        # Após convs/pools, o tamanho típico de saída é 16x4x4 (para entrada 28x28)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        #testar se fica melhor com o dropout\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_lenet5(num_classes=10):\n",
        "        \"\"\"\n",
        "        Retorna uma instância da LeNet-5 pura (sem wrapper do Model).\n",
        "        \"\"\"\n",
        "        class LeNet5(nn.Module):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "                self.pool = nn.AvgPool2d(2)\n",
        "                self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "                self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "                self.fc2 = nn.Linear(120, 84)\n",
        "                self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = F.relu(self.conv1(x))\n",
        "                x = self.pool(x)\n",
        "                x = F.relu(self.conv2(x))\n",
        "                x = self.pool(x)\n",
        "                x = x.view(x.size(0), -1)\n",
        "                x = F.relu(self.fc1(x))\n",
        "                x = F.relu(self.fc2(x))\n",
        "                x = self.fc3(x)\n",
        "                return x\n",
        "\n",
        "        return LeNet5()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Fluxo da LeNet-5\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7n2tpSUA-FBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Chamar flautim.pytorch.centralized.Experiment para experimento centralizado\n",
        "from flautim.pytorch.centralized.Experiment import Experiment\n",
        "\n",
        "import flautim2 as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "class Experiment(Experiment):\n",
        "    def __init__(self, model, dataset, context, **kwargs):\n",
        "        super(Experiment, self).__init__(model, dataset, context, **kwargs)\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
        "        self.epochs = kwargs.get('epochs', 30)\n",
        "\n",
        "\n",
        "    def training_loop(self, data_loader):\n",
        "        self.model.train()\n",
        "        error_loss = 0.0\n",
        "        yhat, y_real = [], []\n",
        "\n",
        "        for X, y in data_loader:\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(X)\n",
        "            loss = self.criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            error_loss += loss.cpu().item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            yhat.append(predicted.detach().cpu())\n",
        "            y_real.append(y.detach().cpu())\n",
        "\n",
        "        accuracy = self.metrics.ACCURACY(torch.cat(yhat).numpy(), torch.cat(y_real).numpy())\n",
        "        accuracy_2 = self.metrics.ACCURACY_2(torch.cat(yhat).numpy(), torch.cat(y_real).numpy())\n",
        "        error_loss = error_loss / len(data_loader)\n",
        "\n",
        "        return float(error_loss), {'ACCURACY': accuracy, 'ACCURACY_2': accuracy_2}\n",
        "\n",
        "    def validation_loop(self, data_loader):\n",
        "        error_loss = 0.0\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in data_loader:\n",
        "                outputs = self.model(X)\n",
        "                error_loss += self.criterion(outputs, y).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                yhat.append(predicted.detach().cpu())\n",
        "            y_real.append(y.detach().cpu())\n",
        "\n",
        "        accuracy = self.metrics.ACCURACY(torch.cat(yhat).numpy(), torch.cat(y_real).numpy())\n",
        "        accuracy_2 = self.metrics.ACCURACY_2(torch.cat(yhat).numpy(), torch.cat(y_real).numpy())\n",
        "        error_loss = error_loss / len(data_loader)\n",
        "\n",
        "        return float(error_loss), {'ACCURACY': accuracy, 'ACCURACY_2': accuracy_2}"
      ],
      "metadata": {
        "id": "QgwcsqlP-IXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbEQqD7d9-Gt"
      },
      "outputs": [],
      "source": [
        "#Determinar qual dataset para aí sim eu mexer aqui, vamo começar com qual?\n",
        "from flautim2.pytorch.Dataset import Dataset\n",
        "import torch\n",
        "import copy\n",
        "\n",
        "class IRISDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file, **kwargs):\n",
        "        super(IRISDataset, self).__init__(name = \"IRIS\", **kwargs)\n",
        "\n",
        "        # Defina o que são features e targets\n",
        "        self.features = file.iloc[:, 0:4].values\n",
        "        self.target = file.iloc[:, 4].values\n",
        "\n",
        "        # Número de amostras para teste\n",
        "        self.test_size = int(0.2 * len(file))\n",
        "\n",
        "        # Defina o tipo do tensor de entrada e de saída.\n",
        "        self.xdtype = torch.float32\n",
        "        self.ydtype = torch.int64\n",
        "\n",
        "        # batch_size\n",
        "        self.batch_size = 10\n",
        "\n",
        "        # shuffle\n",
        "        self.shuffle = True\n",
        "\n",
        "        # num_workers\n",
        "        self.num_workers = 1\n",
        "\n",
        "    def train(self) -> Dataset:\n",
        "        # Separação das amostras para treino\n",
        "        self.features = self.features[:-self.test_size]\n",
        "        self.target = self.target[:-self.test_size]\n",
        "        return copy.deepcopy(self)\n",
        "\n",
        "    def validation(self) -> Dataset:\n",
        "        # Separação das amostras para validação\n",
        "        self.features = self.features[-self.test_size:]\n",
        "        self.target = self.target[-self.test_size:]\n",
        "        return copy.deepcopy(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.LongTensor([self.target[idx]])"
      ]
    }
  ]
}